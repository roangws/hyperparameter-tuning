{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a8a7a0",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<h2>Hyperparameter Tuning</h2>\n",
    "<h4>Roan G. W. Salgueiro</h4>\n",
    "\n",
    "<br>\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb8e6f",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<br>\n",
    "In this project I will tuning the hyperparameters of two of the following model types:\n",
    "\n",
    "* Regression Tree\n",
    "* Random Forest\n",
    "* Gradient Boosted Machine (GBM)\n",
    "\n",
    "Hyperparameters are parameters that are set before training the model and affect the behavior of the model during training. Tuning hyperparameters involves selecting the best combination of hyperparameters that lead to the highest performance of the model on the given dataset.\n",
    "\n",
    "To tune the hyperparameters, I'll need to experiment with different values for each hyperparameter and evaluate the performance of the model for each combination of hyperparameters. I'll use techniques such as cross-validation to evaluate the performance of the model on different subsets of the data.\n",
    "\n",
    "Once I have selected the best hyperparameters for each model, I'll need to evaluate the performance of the models on a holdout dataset. This dataset is separate from the dataset used for tuning the hyperparameters and is used to estimate the generalization performance of the models.\n",
    "\n",
    "Overall, the goal of this project is to demonstrate my ability to apply machine learning techniques to real-world problems by tuning the hyperparameters of these models to achieve the best possible performance.\n",
    "\n",
    "<h3>Step 1: Imports</h3>\n",
    "Import the following packages and make sure to start replacing my comments with your own. Also, please tell me about which models you are tuning in the second cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7173da84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Overall_Qual</th>\n",
       "      <th>Overall_Cond</th>\n",
       "      <th>Mas_Vnr_Area</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>First_Flr_SF</th>\n",
       "      <th>Second_Flr_SF</th>\n",
       "      <th>Gr_Liv_Area</th>\n",
       "      <th>Full_Bath</th>\n",
       "      <th>Half_Bath</th>\n",
       "      <th>Kitchen_AbvGr</th>\n",
       "      <th>TotRms_AbvGr</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>Garage_Cars</th>\n",
       "      <th>Garage_Area</th>\n",
       "      <th>Porch_Area</th>\n",
       "      <th>Pool_Area</th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>log_Sale_Price</th>\n",
       "      <th>log_Lot_Area</th>\n",
       "      <th>log_Mas_Vnr_Area</th>\n",
       "      <th>m_Mas_Vnr_Area</th>\n",
       "      <th>m_Total_Bsmt_SF</th>\n",
       "      <th>m_Garage_Cars</th>\n",
       "      <th>m_Garage_Area</th>\n",
       "      <th>m_log_Mas_Vnr_Area</th>\n",
       "      <th>has_Second_Flr</th>\n",
       "      <th>has_Garage</th>\n",
       "      <th>has_Mas_Vnr</th>\n",
       "      <th>has_Porch</th>\n",
       "      <th>log_Overall_Qual</th>\n",
       "      <th>Total_Bath</th>\n",
       "      <th>Grvl</th>\n",
       "      <th>Pave</th>\n",
       "      <th>Corner</th>\n",
       "      <th>CulDSac</th>\n",
       "      <th>FR2</th>\n",
       "      <th>FR3</th>\n",
       "      <th>Inside</th>\n",
       "      <th>Blmngtn</th>\n",
       "      <th>Blueste</th>\n",
       "      <th>BrDale</th>\n",
       "      <th>BrkSide</th>\n",
       "      <th>ClearCr</th>\n",
       "      <th>CollgCr</th>\n",
       "      <th>Crawfor</th>\n",
       "      <th>Edwards</th>\n",
       "      <th>Gilbert</th>\n",
       "      <th>Greens</th>\n",
       "      <th>GrnHill</th>\n",
       "      <th>IDOTRR</th>\n",
       "      <th>Landmrk</th>\n",
       "      <th>MeadowV</th>\n",
       "      <th>Mitchel</th>\n",
       "      <th>NAmes</th>\n",
       "      <th>NPkVill</th>\n",
       "      <th>NWAmes</th>\n",
       "      <th>NoRidge</th>\n",
       "      <th>NridgHt</th>\n",
       "      <th>OldTown</th>\n",
       "      <th>SWISU</th>\n",
       "      <th>Sawyer</th>\n",
       "      <th>SawyerW</th>\n",
       "      <th>Somerst</th>\n",
       "      <th>StoneBr</th>\n",
       "      <th>Timber</th>\n",
       "      <th>Veenker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>112</td>\n",
       "      <td>1080</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>1656</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>528</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>215000</td>\n",
       "      <td>12.278393</td>\n",
       "      <td>10.366278</td>\n",
       "      <td>4.718508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>882</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>105000</td>\n",
       "      <td>11.561716</td>\n",
       "      <td>9.360655</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>1329</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "      <td>172000</td>\n",
       "      <td>12.055250</td>\n",
       "      <td>9.565704</td>\n",
       "      <td>4.682140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2110</td>\n",
       "      <td>2110</td>\n",
       "      <td>0</td>\n",
       "      <td>2110</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244000</td>\n",
       "      <td>12.404924</td>\n",
       "      <td>9.320091</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>928</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>1629</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>482</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>189900</td>\n",
       "      <td>12.154253</td>\n",
       "      <td>9.534595</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order  Lot_Area  Overall_Qual  Overall_Cond  Mas_Vnr_Area  Total_Bsmt_SF  First_Flr_SF  Second_Flr_SF  Gr_Liv_Area  Full_Bath  Half_Bath  Kitchen_AbvGr  TotRms_AbvGr  Fireplaces  Garage_Cars  Garage_Area  Porch_Area  Pool_Area  Sale_Price  log_Sale_Price  log_Lot_Area  log_Mas_Vnr_Area  m_Mas_Vnr_Area  m_Total_Bsmt_SF  m_Garage_Cars  m_Garage_Area  m_log_Mas_Vnr_Area  has_Second_Flr  has_Garage  has_Mas_Vnr  has_Porch  log_Overall_Qual  Total_Bath  Grvl  Pave  Corner  CulDSac  FR2  FR3  Inside  Blmngtn  Blueste  BrDale  BrkSide  ClearCr  CollgCr  Crawfor  Edwards  Gilbert  Greens  GrnHill  IDOTRR  Landmrk  MeadowV  Mitchel  NAmes  NPkVill  NWAmes  NoRidge  NridgHt  OldTown  SWISU  Sawyer  SawyerW  Somerst  StoneBr  Timber  Veenker\n",
       "0      1     31770             6             5           112           1080          1656              0         1656          1          0              1             7           2            2          528         272          0      215000       12.278393     10.366278          4.718508               0                0              0              0                   0               0           1            1          1          1.791759         1.0     0     1       1        0    0    0       0        0        0       0        0        0        0        0        0        0       0        0       0        0        0        0      1        0       0        0        0        0      0       0        0        0        0       0        0\n",
       "1      2     11622             5             6             0            882           896              0          896          1          0              1             5           0            1          730         260          0      105000       11.561716      9.360655         -6.907755               0                0              0              0                   0               0           1            0          1          1.609438         1.0     0     1       0        0    0    0       1        0        0       0        0        0        0        0        0        0       0        0       0        0        0        0      1        0       0        0        0        0      0       0        0        0        0       0        0\n",
       "2      3     14267             6             6           108           1329          1329              0         1329          1          1              1             6           0            1          312         429          0      172000       12.055250      9.565704          4.682140               0                0              0              0                   0               0           1            1          1          1.791759         1.5     0     1       1        0    0    0       0        0        0       0        0        0        0        0        0        0       0        0       0        0        0        0      1        0       0        0        0        0      0       0        0        0        0       0        0\n",
       "3      4     11160             7             5             0           2110          2110              0         2110          2          1              1             8           2            2          522           0          0      244000       12.404924      9.320091         -6.907755               0                0              0              0                   0               0           1            0          0          1.945910         2.5     0     1       1        0    0    0       0        0        0       0        0        0        0        0        0        0       0        0       0        0        0        0      1        0       0        0        0        0      0       0        0        0        0       0        0\n",
       "4      5     13830             5             5             0            928           928            701         1629          2          1              1             6           1            2          482         246          0      189900       12.154253      9.534595         -6.907755               0                0              0              0                   0               1           1            0          1          1.609438         2.5     0     1       0        0    0    0       1        0        0       0        0        0        0        0        0        1       0        0       0        0        0        0      0        0       0        0        0        0      0       0        0        0        0       0        0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing related libraries \n",
    "import numpy             as np\n",
    "import pandas            as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "\n",
    "\n",
    "# importing model types\n",
    "import sklearn.linear_model                            # importing linear models \n",
    "from sklearn.tree     import DecisionTreeRegressor     # impoting regression trees models \n",
    "from sklearn.ensemble import RandomForestRegressor     # importing random forest models \n",
    "from sklearn.ensemble import GradientBoostingRegressor # importing GBM model \n",
    "\n",
    "\n",
    "# importing ML tools\n",
    "from sklearn.model_selection import train_test_split   # importing train test split package\n",
    "from sklearn.model_selection import RandomizedSearchCV # hyperparameter tuning\n",
    "\n",
    "# loading data to housing variable \n",
    "housing = pd.read_excel('./__datasets/housing_feature_rich.xlsx')\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "########################################\n",
    "# x-variable sets\n",
    "########################################\n",
    "\n",
    "x_variables = ['Garage_Cars', 'Overall_Qual', 'Total_Bsmt_SF',\n",
    "               'NridgHt', 'Kitchen_AbvGr', 'has_Second_Flr',\n",
    "               'Mas_Vnr_Area', 'has_Garage', 'Porch_Area',\n",
    "               'NWAmes', 'OldTown', 'Overall_Cond',\n",
    "               'Edwards', 'Somerst', 'Fireplaces',\n",
    "               'Second_Flr_SF', 'First_Flr_SF', 'has_Mas_Vnr',\n",
    "               'CulDSac', 'Total_Bath', 'Crawfor', 'Garage_Area',\n",
    "               'has_Porch']\n",
    "\n",
    "\n",
    "full_x = ['Overall_Qual', 'Overall_Cond', 'Mas_Vnr_Area', 'Total_Bsmt_SF',\n",
    "          'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Full_Bath',\n",
    "          'Half_Bath', 'Kitchen_AbvGr', 'TotRms_AbvGr', 'Fireplaces',\n",
    "          'Garage_Cars', 'Garage_Area', 'Porch_Area', 'log_Lot_Area',\n",
    "          'has_Second_Flr', 'has_Garage', 'has_Mas_Vnr', 'has_Porch',\n",
    "          'Total_Bath', 'CulDSac', 'BrkSide', 'CollgCr', 'Crawfor',\n",
    "          'Edwards', 'Gilbert', 'Mitchel', 'NWAmes', 'NridgHt', 'OldTown',\n",
    "          'Sawyer', 'SawyerW', 'Somerst', 'Other_NH']\n",
    "\n",
    "\n",
    "reduced_x = ['Overall_Qual', 'Gr_Liv_Area', 'Full_Bath',\n",
    "             'Kitchen_AbvGr', 'TotRms_AbvGr', 'Fireplaces',\n",
    "             'Garage_Cars', 'Garage_Area', 'Porch_Area', \n",
    "             'log_Lot_Area', 'has_Second_Flr', 'has_Garage',\n",
    "             'has_Mas_Vnr', 'has_Porch', 'Total_Bath', 'CulDSac']\n",
    "\n",
    "# checking results\n",
    "housing.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0099269b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7602f90c",
   "metadata": {},
   "source": [
    "Which models are you tuning?\n",
    "\n",
    "Our team is tuning \"Random Forest\" and \"Gradient Boosted Machine\" models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daaf31f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 2: Train-Test Split</h3>\n",
    "Set up train-test split in the cell below. Set your <em>test_size</em> to 0.25 and your <em>random_state</em> to 219."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf81991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing x-varaibles (dropping the y variables from the dataset)\n",
    "x_data = housing.drop(['Sale_Price','log_Sale_Price'],axis = 1)\n",
    "\n",
    "# preparing y-variable \n",
    "y_data = housing.loc[ : , 'Sale_Price']\n",
    "\n",
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, \n",
    "                                                    y_data,\n",
    "                                                    test_size    = 0.25,\n",
    "                                                    random_state = 219)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095cc33",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 3: Check Available Hyperparameters</h3>\n",
    "Call help(&nbsp;) on your selected model types to see which hyperparameters are available for tuning. Do NOT tune random_state, n_jobs or anything related to the intercept of a model. Use as many cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92b46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert additional cells to call help() on each of your models\n",
    "# help(DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0184a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(GradientBoostingRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f9ef5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 4: Model Development - Default Hyperparameters</h3>\n",
    "Run each of your selected models using three (3) respective default hyperparameters that you feel would be good candidates for optimization, printing their R-Square values for the training and testing sets. Use as many cells as needed and make sure to label your default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1bc5688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "DecisionTree model with default hyperparameters \n",
      "\n",
      "Train R-Square value: 1.0\n",
      "Test R-Square value: 0.7473218270728141\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 1 - DecisionTree with default hyperparameters \n",
    "\n",
    "# Instantiating a DecisionTree model with default values \n",
    "dt_1 = DecisionTreeRegressor(criterion    = 'squared_error', # Setting the criterion as default value 'squared_error'\n",
    "                             splitter     = 'best',          # Setting the splitter as default value 'best'\n",
    "                             max_depth    = None,            # Setting the max_depth as default value None\n",
    "                             random_state = 219)             # Setting the random_state \n",
    "\n",
    "# Fitting the training data into the model \n",
    "dt_1.fit(x_train, y_train)\n",
    "# Predicting based on the testing set \n",
    "dt_1.predict(x_test)\n",
    "# Scoring the result for training data and testing data \n",
    "dt_1_train_score = dt_1.score(x_train, y_train)\n",
    "dt_1_test_score  = dt_1.score(x_test, y_test)\n",
    "\n",
    "# Printing the R-squared values for the training and testing score \n",
    "print(f\"\"\"\n",
    "{'*' * 80}\n",
    "DecisionTree model with default hyperparameters \\n\n",
    "Train R-Square value: {dt_1_train_score}\n",
    "Test R-Square value: {dt_1_test_score}\n",
    "{'*' * 80}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28398afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "Gradient Boosting Machine model with default hyperparameters \n",
      "\n",
      "Train R-Square value: 0.9481756836545663\n",
      "Test R-Square value:  0.8912790360095459\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 2 - Gradient Boosted Machine with default hyperparameters \n",
    "\n",
    "# Instantiating a DecisionTree model with default values \n",
    "GBM_1 = GradientBoostingRegressor(loss          = 'squared_error',# Setting the loss as default value 'squared_error\n",
    "                                  learning_rate = 0.1,            # Setting the learning_rate as default value 0.1\n",
    "                                  n_estimators  = 100,            # Setting the n_estimators as default value 100\n",
    "                                  random_state  = 219)            # Setting the random_state\n",
    "\n",
    "# Fitting the training data into the model \n",
    "GBM_1.fit(x_train, y_train)\n",
    "# Predicting based on the testing set \n",
    "GBM_1.predict(x_test)\n",
    "# Scoring the result for training data and testing data \n",
    "GBM_1_training_score = GBM_1.score(x_train, y_train)\n",
    "GBM_1_testing_score  = GBM_1.score(x_test, y_test)\n",
    "\n",
    "# Printing the R-squared values for the training and testing score \n",
    "print(f\"\"\"\n",
    "{'*' * 80}\n",
    "Gradient Boosting Machine model with default hyperparameters \\n\n",
    "Train R-Square value: {GBM_1_training_score}\n",
    "Test R-Square value:  {GBM_1_testing_score}\n",
    "{'*' * 80}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf81be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 5: Hyperparameter Tuning Part I</h3><br>\n",
    "Develop ranges for each of the hyperparameters you would like tune. Write a code to calculate how many models you are building (based on the combinations of hyperparameters you are tuning).\n",
    "<br><br>\n",
    "<strong>Requirement:</strong> You must tune at least three hyperparameters per model.<br>\n",
    "<strong>Recommendation:</strong> Keep the number of models (i.e., iterations) you are building to:\n",
    "\n",
    "* Less than 2,000 for Random Forest and GBM  (not including cross-validation)\n",
    "* Less than 10,000 for all other model types (not including cross-validation)\n",
    "\n",
    "Insert as many code cells as you need for the number of model types you are tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c074ee",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning for Model 1 - Decision Tree\n",
    "\n",
    "# Declaring a hyperparameter space\n",
    "splitter_range  = ['best','random']         # setting two types of splitter      \n",
    "depth_range     = range(1,60,2)             # setting max depth range \n",
    "leaf_range      = range(2,50,2)             # setting min samples split range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe5ca797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of model combinations for Decision Tree: \n",
      "1440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The number of model combinations for Model 1 - Decision Tree\n",
    "print(f\"\"\"\n",
    "The number of model combinations for Decision Tree: \n",
    "{len(depth_range)*len(splitter_range)*len(leaf_range)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c127a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning for Model 2 - Gradient Boosted Machine \n",
    "\n",
    "# Declaring a hyperparameter space \n",
    "learn_rate = np.linspace(0.1,1,10)        # setting learning rate range from 0.1 to 1 step 10 \n",
    "\n",
    "n_estimators = range(1,50,5)              # setting n_estimator range\n",
    "\n",
    "min_sample_split = range(2,20,2)          # setting min sample split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0806cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of model combinations for GBM : \n",
      "900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The number of model combinations for Model 2 - GBM\n",
    "print(f\"\"\"\n",
    "The number of model combinations for GBM : \n",
    "{len(learn_rate)*len(n_estimators)*len(min_sample_split)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdfe6ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 6: Hyperparameter Tuning Part II</h3><br>\n",
    "Create a hyperparameter grid for each of the models you are tuning. Note that this is the dictionary step we conducted in class. Use as many cells as needed for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69c3cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for Model 1 - Decision Tree\n",
    "param_grid_1 = {'splitter'         : splitter_range,\n",
    "                'max_depth'        : depth_range,\n",
    "                'min_samples_split': leaf_range}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f0ca0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for Model 2 - GBM\n",
    "param_grid_2 = {'learning_rate'    : learn_rate,\n",
    "                'n_estimators'     : n_estimators,\n",
    "                'min_samples_split': min_sample_split}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ec44b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Step 7: Hyperparameter Tuning Part III</h3><br>\n",
    "a) Complete the remaining steps for hyperparameter tuning. While your code runs, observe the processing time it takes to tune. Use as many cells as needed for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3aa9f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters: {'splitter': 'random', 'min_samples_split': 20, 'max_depth': 11}\n",
      "Tuned Training R-square: 0.815\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the model object with DecisionTreeRegressor\n",
    "tuned_tree = DecisionTreeRegressor(random_state = 219)\n",
    "\n",
    "# RandomizedSearchCV object\n",
    "tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "                                   param_distributions   = param_grid_1,\n",
    "                                   cv                    = 5,\n",
    "                                   n_iter                = 1000,\n",
    "                                   random_state          = 219)\n",
    "\n",
    "# Fitting to the full dataset(due to cross-validation)\n",
    "tuned_tree_cv.fit(x_data, y_data)\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters:\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training R-square:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "249cb5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters: {'n_estimators': 36, 'min_samples_split': 6, 'learning_rate': 0.2}\n",
      "Tuned Training R-square: 0.8836\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the model object with GradientBoostingRegressor \n",
    "tuned_GBM = GradientBoostingRegressor(random_state = 219)\n",
    "\n",
    "# RandomizedSearchCV object\n",
    "tuned_GBM_cv = RandomizedSearchCV(estimator              = tuned_GBM,\n",
    "                                   param_distributions   = param_grid_2,\n",
    "                                   cv                    = 5,\n",
    "                                   n_iter                = 50,\n",
    "                                   random_state          = 219)\n",
    "\n",
    "# Fitting to the full dataset(due to cross-validation)\n",
    "tuned_GBM_cv.fit(x_data, y_data)\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters:\", tuned_GBM_cv.best_params_)\n",
    "print(\"Tuned Training R-square:\", tuned_GBM_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3102d91",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>\n",
    "b) Explore the hyperparameter tuning results for one of your tuned models. Look for hyperparameter combinations that tied for first place. Test each of these models using train-test split. If no models tied for first place, test your top three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d1a2c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.15069723, 0.05830998, 0.10091496, 0.2546123 , 0.46881542,\n",
       "        0.52552605, 0.10773902, 0.15252156, 0.48887677, 0.14369102,\n",
       "        0.1881968 , 0.13732963, 0.01167507, 0.26431465, 0.1366313 ,\n",
       "        0.25632477, 0.2199214 , 0.17286224, 0.20985751, 0.0117135 ,\n",
       "        0.13029952, 0.32587047, 0.28848257, 0.21019077, 0.13145065,\n",
       "        0.08816695, 0.13939633, 0.33560443, 0.25250216, 0.33161664,\n",
       "        0.29489231, 0.18280497, 0.26371622, 0.14305611, 0.28741961,\n",
       "        0.28917518, 0.0548152 , 0.06031928, 0.41755013, 0.10124521,\n",
       "        0.31708341, 0.01182418, 0.19343662, 0.31915331, 0.22773199,\n",
       "        0.05414805, 0.32730522, 0.18503714, 0.0121419 , 0.26741681]),\n",
       " 'std_fit_time': array([0.11560738, 0.001254  , 0.00603545, 0.01363939, 0.09392682,\n",
       "        0.17707103, 0.00375738, 0.00452022, 0.16747994, 0.00512376,\n",
       "        0.00157944, 0.00431057, 0.00057448, 0.00539291, 0.00558715,\n",
       "        0.00420009, 0.01146357, 0.00747444, 0.00251041, 0.00049074,\n",
       "        0.00312799, 0.00507842, 0.00405267, 0.004705  , 0.00177664,\n",
       "        0.00126071, 0.00913307, 0.01873714, 0.00547423, 0.0116186 ,\n",
       "        0.00742819, 0.01267004, 0.05670785, 0.00537461, 0.00805645,\n",
       "        0.00981264, 0.00061049, 0.00203976, 0.00728572, 0.00454116,\n",
       "        0.00902297, 0.00037697, 0.00813994, 0.01178793, 0.00641844,\n",
       "        0.00150758, 0.01281187, 0.00282893, 0.00061456, 0.00777683]),\n",
       " 'mean_score_time': array([0.00563874, 0.00284734, 0.00276484, 0.00275211, 0.00358038,\n",
       "        0.02324057, 0.00356622, 0.00305758, 0.00334601, 0.00259457,\n",
       "        0.0029192 , 0.00284257, 0.00242081, 0.00266819, 0.00283799,\n",
       "        0.00290937, 0.00258355, 0.00256438, 0.00251756, 0.00277791,\n",
       "        0.00238342, 0.00263152, 0.0031498 , 0.00279331, 0.00260644,\n",
       "        0.0025106 , 0.0030148 , 0.00274034, 0.0026691 , 0.00257864,\n",
       "        0.00288711, 0.002737  , 0.00275927, 0.00310931, 0.00360847,\n",
       "        0.00301094, 0.00271435, 0.00267897, 0.0028636 , 0.00270844,\n",
       "        0.0028614 , 0.00287671, 0.00280666, 0.00280986, 0.00266471,\n",
       "        0.00270181, 0.00291677, 0.00308084, 0.00294609, 0.00274277]),\n",
       " 'std_score_time': array([3.33018405e-03, 5.03384673e-04, 3.05448373e-04, 3.00205041e-04,\n",
       "        9.11465408e-04, 3.99114377e-02, 9.68824901e-04, 4.05393216e-04,\n",
       "        5.70680922e-04, 1.06632943e-04, 4.92081554e-04, 4.87112219e-04,\n",
       "        9.56222706e-05, 2.15582472e-04, 3.64785774e-04, 4.16685547e-04,\n",
       "        2.78903289e-04, 2.46527043e-04, 2.25301626e-04, 1.05512903e-03,\n",
       "        5.90507328e-05, 6.73758587e-05, 9.29905111e-04, 8.09592840e-04,\n",
       "        3.18584944e-04, 3.71984924e-04, 5.49026088e-04, 5.02100865e-04,\n",
       "        1.36213356e-04, 1.58773069e-04, 6.03146920e-04, 2.42669940e-04,\n",
       "        3.14091243e-04, 6.79867685e-04, 6.22478667e-04, 2.82282942e-04,\n",
       "        2.84783878e-04, 2.53644274e-04, 1.60788853e-04, 3.43319840e-04,\n",
       "        2.11831042e-04, 6.66820314e-04, 2.47475591e-04, 6.58502620e-05,\n",
       "        9.95227348e-05, 2.25268563e-04, 3.57822442e-04, 4.19688300e-04,\n",
       "        4.63839860e-04, 2.79063218e-04]),\n",
       " 'param_n_estimators': masked_array(data=[6, 6, 11, 26, 46, 46, 11, 16, 41, 16, 21, 16, 1, 31,\n",
       "                    16, 31, 26, 21, 26, 1, 16, 41, 36, 26, 16, 11, 16, 41,\n",
       "                    31, 41, 36, 21, 26, 16, 31, 31, 6, 6, 46, 11, 36, 1,\n",
       "                    21, 36, 26, 6, 36, 21, 1, 31],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[4, 2, 18, 8, 14, 8, 8, 6, 10, 10, 2, 2, 2, 2, 16, 6,\n",
       "                    10, 14, 14, 6, 14, 8, 6, 12, 2, 8, 8, 2, 4, 12, 6, 6,\n",
       "                    4, 16, 2, 10, 6, 4, 4, 6, 4, 8, 14, 6, 18, 4, 10, 6, 2,\n",
       "                    8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.7000000000000001, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.5, 0.30000000000000004, 0.1,\n",
       "                    0.8, 0.5, 0.5, 0.5, 0.5, 0.1, 1.0, 0.7000000000000001,\n",
       "                    0.9, 0.1, 0.6, 1.0, 0.5, 0.4, 0.4, 0.5,\n",
       "                    0.7000000000000001, 1.0, 0.5, 0.2, 0.5, 0.8, 0.8, 0.8,\n",
       "                    0.2, 0.2, 0.5, 1.0, 0.6, 0.30000000000000004, 0.8, 0.2,\n",
       "                    0.30000000000000004, 0.7000000000000001, 1.0, 0.2, 0.5,\n",
       "                    0.1, 0.6, 0.5, 0.9, 0.4, 0.8, 0.6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 6,\n",
       "   'min_samples_split': 4,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'n_estimators': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'n_estimators': 11,\n",
       "   'min_samples_split': 18,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'n_estimators': 26, 'min_samples_split': 8, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 46,\n",
       "   'min_samples_split': 14,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'n_estimators': 46, 'min_samples_split': 8, 'learning_rate': 0.1},\n",
       "  {'n_estimators': 11, 'min_samples_split': 8, 'learning_rate': 0.8},\n",
       "  {'n_estimators': 16, 'min_samples_split': 6, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 41, 'min_samples_split': 10, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 16, 'min_samples_split': 10, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 21, 'min_samples_split': 2, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 16, 'min_samples_split': 2, 'learning_rate': 0.1},\n",
       "  {'n_estimators': 1, 'min_samples_split': 2, 'learning_rate': 1.0},\n",
       "  {'n_estimators': 31,\n",
       "   'min_samples_split': 2,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'n_estimators': 16, 'min_samples_split': 16, 'learning_rate': 0.9},\n",
       "  {'n_estimators': 31, 'min_samples_split': 6, 'learning_rate': 0.1},\n",
       "  {'n_estimators': 26, 'min_samples_split': 10, 'learning_rate': 0.6},\n",
       "  {'n_estimators': 21, 'min_samples_split': 14, 'learning_rate': 1.0},\n",
       "  {'n_estimators': 26, 'min_samples_split': 14, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 1, 'min_samples_split': 6, 'learning_rate': 0.4},\n",
       "  {'n_estimators': 16, 'min_samples_split': 14, 'learning_rate': 0.4},\n",
       "  {'n_estimators': 41, 'min_samples_split': 8, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 36,\n",
       "   'min_samples_split': 6,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'n_estimators': 26, 'min_samples_split': 12, 'learning_rate': 1.0},\n",
       "  {'n_estimators': 16, 'min_samples_split': 2, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 11, 'min_samples_split': 8, 'learning_rate': 0.2},\n",
       "  {'n_estimators': 16, 'min_samples_split': 8, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 41, 'min_samples_split': 2, 'learning_rate': 0.8},\n",
       "  {'n_estimators': 31, 'min_samples_split': 4, 'learning_rate': 0.8},\n",
       "  {'n_estimators': 41, 'min_samples_split': 12, 'learning_rate': 0.8},\n",
       "  {'n_estimators': 36, 'min_samples_split': 6, 'learning_rate': 0.2},\n",
       "  {'n_estimators': 21, 'min_samples_split': 6, 'learning_rate': 0.2},\n",
       "  {'n_estimators': 26, 'min_samples_split': 4, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 16, 'min_samples_split': 16, 'learning_rate': 1.0},\n",
       "  {'n_estimators': 31, 'min_samples_split': 2, 'learning_rate': 0.6},\n",
       "  {'n_estimators': 31,\n",
       "   'min_samples_split': 10,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'n_estimators': 6, 'min_samples_split': 6, 'learning_rate': 0.8},\n",
       "  {'n_estimators': 6, 'min_samples_split': 4, 'learning_rate': 0.2},\n",
       "  {'n_estimators': 46,\n",
       "   'min_samples_split': 4,\n",
       "   'learning_rate': 0.30000000000000004},\n",
       "  {'n_estimators': 11,\n",
       "   'min_samples_split': 6,\n",
       "   'learning_rate': 0.7000000000000001},\n",
       "  {'n_estimators': 36, 'min_samples_split': 4, 'learning_rate': 1.0},\n",
       "  {'n_estimators': 1, 'min_samples_split': 8, 'learning_rate': 0.2},\n",
       "  {'n_estimators': 21, 'min_samples_split': 14, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 36, 'min_samples_split': 6, 'learning_rate': 0.1},\n",
       "  {'n_estimators': 26, 'min_samples_split': 18, 'learning_rate': 0.6},\n",
       "  {'n_estimators': 6, 'min_samples_split': 4, 'learning_rate': 0.5},\n",
       "  {'n_estimators': 36, 'min_samples_split': 10, 'learning_rate': 0.9},\n",
       "  {'n_estimators': 21, 'min_samples_split': 6, 'learning_rate': 0.4},\n",
       "  {'n_estimators': 1, 'min_samples_split': 2, 'learning_rate': 0.8},\n",
       "  {'n_estimators': 31, 'min_samples_split': 8, 'learning_rate': 0.6}],\n",
       " 'split0_test_score': array([0.85355392, 0.81680102, 0.8725732 , 0.86506032, 0.88600965,\n",
       "        0.88215571, 0.84376334, 0.86098013, 0.85728045, 0.86098013,\n",
       "        0.86339588, 0.78281605, 0.72171505, 0.85843143, 0.84225355,\n",
       "        0.86553473, 0.87888578, 0.85757258, 0.88340768, 0.42410403,\n",
       "        0.87692343, 0.86544414, 0.86615365, 0.85725965, 0.85806259,\n",
       "        0.83016226, 0.86098013, 0.84278306, 0.85240642, 0.845579  ,\n",
       "        0.8903195 , 0.87878905, 0.86378216, 0.8510124 , 0.89006655,\n",
       "        0.87638   , 0.83765769, 0.72397273, 0.88357737, 0.86780302,\n",
       "        0.79374964, 0.21974478, 0.88208199, 0.87364426, 0.87141627,\n",
       "        0.86569985, 0.78876447, 0.88558761, 0.67508917, 0.87540379]),\n",
       " 'split1_test_score': array([0.84835925, 0.84453387, 0.88627212, 0.88817626, 0.90321825,\n",
       "        0.89874512, 0.86051829, 0.88117148, 0.88618343, 0.88117148,\n",
       "        0.88901373, 0.82677498, 0.72320369, 0.86260784, 0.84611504,\n",
       "        0.88711725, 0.88500515, 0.85297408, 0.8850212 , 0.48960128,\n",
       "        0.88588136, 0.88799099, 0.87142573, 0.84627517, 0.88996766,\n",
       "        0.86690018, 0.88117148, 0.88981568, 0.88029091, 0.88008852,\n",
       "        0.9040207 , 0.89624671, 0.88774091, 0.8517631 , 0.88747312,\n",
       "        0.90126313, 0.84015312, 0.77799365, 0.90121633, 0.86989417,\n",
       "        0.8519238 , 0.27689834, 0.88702634, 0.89240345, 0.88348383,\n",
       "        0.86741909, 0.86966725, 0.88927354, 0.71275395, 0.88068795]),\n",
       " 'split2_test_score': array([0.82234686, 0.79937741, 0.84441424, 0.87292078, 0.86769841,\n",
       "        0.86456894, 0.82770552, 0.86388082, 0.86747557, 0.86388082,\n",
       "        0.86144345, 0.77385665, 0.68168009, 0.86326792, 0.84737758,\n",
       "        0.84725726, 0.8614482 , 0.81522654, 0.86777578, 0.45598417,\n",
       "        0.86603775, 0.87303908, 0.87104773, 0.81157625, 0.85331056,\n",
       "        0.82753442, 0.86388082, 0.86649251, 0.84112626, 0.85813411,\n",
       "        0.87503377, 0.86082407, 0.86923503, 0.8019849 , 0.85840218,\n",
       "        0.8615205 , 0.8191689 , 0.72919287, 0.87630589, 0.83834071,\n",
       "        0.8155413 , 0.25595731, 0.86975784, 0.85404455, 0.8618543 ,\n",
       "        0.84260965, 0.83335893, 0.8642408 , 0.66884555, 0.85886591]),\n",
       " 'split3_test_score': array([0.79871252, 0.7658794 , 0.81849373, 0.80191668, 0.85154897,\n",
       "        0.83256318, 0.82353998, 0.80405314, 0.81060017, 0.80388772,\n",
       "        0.8084968 , 0.7452116 , 0.6249991 , 0.81952805, 0.79485207,\n",
       "        0.81006024, 0.82533748, 0.77337003, 0.80185888, 0.42329034,\n",
       "        0.8359113 , 0.81092431, 0.82080095, 0.79127094, 0.8035987 ,\n",
       "        0.78208627, 0.80388745, 0.82191664, 0.82674239, 0.83034121,\n",
       "        0.84121103, 0.82223881, 0.81403164, 0.7855508 , 0.81609837,\n",
       "        0.84634081, 0.79563862, 0.69371047, 0.84775571, 0.81928703,\n",
       "        0.79014825, 0.24052681, 0.80906588, 0.82293693, 0.83371621,\n",
       "        0.79509875, 0.80122832, 0.82517692, 0.61552649, 0.82676399]),\n",
       " 'split4_test_score': array([0.86248181, 0.83199834, 0.87818816, 0.87979255, 0.90505045,\n",
       "        0.90049393, 0.85596449, 0.88327731, 0.88439621, 0.88327731,\n",
       "        0.89656618, 0.80638589, 0.71765857, 0.85598706, 0.8648879 ,\n",
       "        0.88322144, 0.86737775, 0.85248399, 0.88950406, 0.47065753,\n",
       "        0.90165135, 0.88439621, 0.85524896, 0.85438526, 0.89246308,\n",
       "        0.8566721 , 0.88327731, 0.84062146, 0.86871684, 0.85027678,\n",
       "        0.90760659, 0.8907953 , 0.88586684, 0.84486384, 0.87176216,\n",
       "        0.90151814, 0.83707499, 0.75232619, 0.89458463, 0.86924771,\n",
       "        0.82308363, 0.2630953 , 0.88660063, 0.89008686, 0.8576925 ,\n",
       "        0.8734725 , 0.86925392, 0.90477235, 0.69793917, 0.86924307]),\n",
       " 'mean_test_score': array([0.83709087, 0.81171801, 0.85998829, 0.86157332, 0.88270515,\n",
       "        0.87570538, 0.84229833, 0.85867258, 0.86118717, 0.85863949,\n",
       "        0.86378321, 0.78700903, 0.6938513 , 0.85196446, 0.83909723,\n",
       "        0.85863819, 0.86361087, 0.83032544, 0.86551352, 0.45272747,\n",
       "        0.87328104, 0.86435895, 0.8569354 , 0.83215346, 0.85948052,\n",
       "        0.83267105, 0.85863944, 0.85232587, 0.85385656, 0.85288392,\n",
       "        0.88363832, 0.86977879, 0.86413132, 0.82703501, 0.86476048,\n",
       "        0.87740452, 0.82593866, 0.73543918, 0.88068799, 0.85291453,\n",
       "        0.81488932, 0.25124451, 0.86690654, 0.86662321, 0.86163262,\n",
       "        0.84885997, 0.83245458, 0.87381024, 0.67403087, 0.86219294]),\n",
       " 'std_test_score': array([0.02337944, 0.02744987, 0.02507909, 0.03078797, 0.02062488,\n",
       "        0.02518801, 0.01473569, 0.02873091, 0.02748572, 0.02879382,\n",
       "        0.03089827, 0.02790837, 0.03766564, 0.01643882, 0.0234545 ,\n",
       "        0.02811511, 0.02085549, 0.03230561, 0.03265985, 0.02599083,\n",
       "        0.02202668, 0.02789892, 0.01898761, 0.0261488 , 0.03218749,\n",
       "        0.02945907, 0.02879392, 0.02349025, 0.01907325, 0.01634618,\n",
       "        0.02411917, 0.02669706, 0.02670578, 0.02775863, 0.02688387,\n",
       "        0.02176697, 0.01689572, 0.02831196, 0.01858287, 0.02059103,\n",
       "        0.02235232, 0.01963605, 0.02958591, 0.02581152, 0.01654143,\n",
       "        0.02885528, 0.03353713, 0.02754359, 0.03323208, 0.01914458]),\n",
       " 'rank_test_score': array([36, 44, 21, 19,  2,  5, 34, 23, 20, 24, 15, 45, 47, 32, 35, 26, 16,\n",
       "        40, 11, 49,  7, 13, 27, 39, 22, 37, 25, 31, 28, 30,  1,  8, 14, 41,\n",
       "        12,  4, 42, 46,  3, 29, 43, 50,  9, 10, 18, 33, 38,  6, 48, 17],\n",
       "       dtype=int32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the hyperparameter tuning results of Gradient Boosting Machine \n",
    "\n",
    "# cross validation results of Gradient Boosting Machine\n",
    "tuned_GBM_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffebbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to analyze tuning result \n",
    "def tuning_results(cv_results, n=1):\n",
    "    \"\"\"\n",
    "This function will display the top \"n\" models from hyperparameter tuning,\n",
    "based on \"rank_test_score\".\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "cv_results = results dictionary from the attribute \".cv_results_\"\n",
    "n          = number of models to display\n",
    "    \"\"\"\n",
    "    param_lst = []\n",
    "\n",
    "    for result in cv_results[\"params\"]:\n",
    "        result = str(result).replace(\":\", \"=\")\n",
    "        param_lst.append(result[1:-1])\n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame(data = {\n",
    "        \"Model_Rank\" : cv_results[\"rank_test_score\"],\n",
    "        \"Mean_Test_Score\" : cv_results[\"mean_test_score\"],\n",
    "        \"SD_Test_Score\" : cv_results[\"std_test_score\"],\n",
    "        \"Parameters\" : param_lst\n",
    "    })\n",
    "\n",
    "\n",
    "    results_df = results_df.sort_values(by = \"Model_Rank\", axis = 0)\n",
    "    return results_df.head(n = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b597a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Rank</th>\n",
       "      <th>Mean_Test_Score</th>\n",
       "      <th>SD_Test_Score</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0.883638</td>\n",
       "      <td>0.024119</td>\n",
       "      <td>'n_estimators'= 36, 'min_samples_split'= 6, 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.882705</td>\n",
       "      <td>0.020625</td>\n",
       "      <td>'n_estimators'= 46, 'min_samples_split'= 14, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>0.880688</td>\n",
       "      <td>0.018583</td>\n",
       "      <td>'n_estimators'= 46, 'min_samples_split'= 4, 'l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model_Rank  Mean_Test_Score  SD_Test_Score                                         Parameters\n",
       "30           1         0.883638       0.024119  'n_estimators'= 36, 'min_samples_split'= 6, 'l...\n",
       "4            2         0.882705       0.020625  'n_estimators'= 46, 'min_samples_split'= 14, '...\n",
       "38           3         0.880688       0.018583  'n_estimators'= 46, 'min_samples_split'= 4, 'l..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run tuning_results() on the hyperparameter tuning results \n",
    "# returning top 3 models \n",
    "tuning_results( cv_results = tuned_GBM_cv.cv_results_, n = 3 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
